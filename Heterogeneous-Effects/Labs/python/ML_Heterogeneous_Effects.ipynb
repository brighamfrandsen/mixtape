{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brighamfrandsen/mixtape/blob/main/Heterogeneous-Effects/Labs/python/ML_Heterogeneous_Effects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSPS7wJ8rRlT"
      },
      "source": [
        "# Causal Effects via Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YNwBN15z9sP"
      },
      "source": [
        "Let's take up the example from the slides: what is the effect of going to a fancy college on later-life earnings? We'll use data on about 1,000 American men in the NLSY born 1980-1984 who finished college, and look at the effect of going to a private college ($D_i$) on earnings ($Y_i$) in 2015-2019 (when they were about 30-39 years old). We will be estimating an equation like this:\n",
        "\n",
        "$$\n",
        "Y_i = \\delta D_i + X_i'\\beta+\\varepsilon_i,\n",
        "$$\n",
        "\n",
        "where $X_i$ is a vector of controls, conditional on which we are willing to assume $D_i$ is as good as randomly assigned.\n",
        "\n",
        "What kinds of variables should we include in $X_i$?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to github repo\n",
        "!git clone https://github.com/Mixtape-Sessions/Heterogeneous-Effects.git\n",
        "%cd Heterogeneous-Effects/Labs"
      ],
      "metadata": {
        "id": "HgNF7UViEHtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxjvdQ6MrwDH"
      },
      "outputs": [],
      "source": [
        "# import useful packages\n",
        "import pandas as pd  # for loading and managing datasets\n",
        "import statsmodels.api as sm  # for running regressions and getting standard errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ4U1cDKr55N"
      },
      "outputs": [],
      "source": [
        "# load NLSY data\n",
        "nlsy = pd.read_csv(\n",
        "    \"data/nlsy97.csv\"\n",
        ")\n",
        "nlsy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLz0OfXpsNke"
      },
      "outputs": [],
      "source": [
        "# clean data (drop obs with missing values)\n",
        "nlsy = nlsy.dropna().copy()\n",
        "nlsy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EZ8-1rb13qR"
      },
      "source": [
        "Let's start with a simple (uncontrolled) regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmJwZcMpsr3N"
      },
      "outputs": [],
      "source": [
        "# Simple regression\n",
        "rhs = sm.add_constant(\n",
        "    nlsy[\"privatecollege\"]\n",
        ")  # you have to add the constant yourself with statsmodels!\n",
        "model = sm.OLS(nlsy[\"annualearnings\"], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")  # heteroskedasticity-robust\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if7mL0Se247R"
      },
      "source": [
        "How to interpret the coefficient on $privatecollege$? As a causal effect?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxN5CIkd3FIc"
      },
      "source": [
        "Now let's add controls for parent's education and cognitive ability as measured by ASVAB:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WAfh6LjQpHh"
      },
      "outputs": [],
      "source": [
        "# Regression with controls\n",
        "rhs = sm.add_constant(nlsy[[\"privatecollege\", \"dadcollege\", \"momcollege\", \"asvab\"]])\n",
        "model = sm.OLS(nlsy[\"annualearnings\"], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdPZTZNU3R13"
      },
      "source": [
        "How did the inclusion of controls change the estimate? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5-ItzrL3W4y"
      },
      "source": [
        "Back to the whiteboard for prediction!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI9XXfGU3dde"
      },
      "source": [
        "# Prediction Primer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7yvgsZ3pz2"
      },
      "source": [
        "Let's use decision trees to predict which participants of the National JTPA Study were likely to find a job. We will use prior earnings, education, sex, race, and marital status as our prediction features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4fQikML3gwD"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\n",
        "    \"data/jtpahet.csv\"\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkytiOpITN_E"
      },
      "source": [
        "Import some utilities:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KORsELfSTMyl"
      },
      "outputs": [],
      "source": [
        "%cd python\n",
        "import plot_helpers\n",
        "import tools\n",
        "import plot_2d_separator\n",
        "import plot_interactive_tree\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcgiIKnqIUt2"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "from sklearn.tree import plot_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nxwcyI0mILm"
      },
      "source": [
        "We'll first grow a tree using just two features (education and prior earnings) so we can visualize it easily. Let's visualize the feature space: triangles are individuals who found a job, circles are those who didn't.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPZ6jMTLmWsg"
      },
      "outputs": [],
      "source": [
        "plot_helpers.discrete_scatter(\n",
        "    data.loc[:, \"educ\"].values,\n",
        "    data.loc[:, \"priorearn\"].values,\n",
        "    data.loc[:, \"foundjob\"].values\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf24rdVLJZmr"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(max_depth=3,class_weight=\"balanced\").fit(\n",
        "    data.loc[:, [\"educ\", \"priorearn\"]].values, data.loc[:, \"foundjob\"].values\n",
        ")\n",
        "fig1, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "plot_interactive_tree.plot_tree_partition(\n",
        "    data.loc[:, [\"educ\", \"priorearn\"]].values,\n",
        "    data.loc[:, \"foundjob\"].values,\n",
        "    tree,\n",
        "    ax=ax,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtATm789RIKv"
      },
      "outputs": [],
      "source": [
        "plot_tree(\n",
        "    tree,\n",
        "    feature_names=[\"education\", \"Prior earnings\"],\n",
        "    class_names=[\"No job\", \"Found job\"],\n",
        "    impurity=False,\n",
        "    filled=True, fontsize=6\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On your own: grow another tree, but without setting `max_depth`, and plot the decision boundary."
      ],
      "metadata": {
        "id": "9yIHxmb7jKU0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9CxF9YuNjT_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well do you think this un-pruned tree fits the training data compared to the simpler tree above? How well do you think the un-pruned tree would predict an out-of-sample observation?"
      ],
      "metadata": {
        "id": "6xzwJxHSjU6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back to the whiteboard!"
      ],
      "metadata": {
        "id": "i6NUU9_rm-pQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmZtyYDnC4V"
      },
      "source": [
        "Now let's do a random forest:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OnAO2PnR3Me"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators=5, random_state=2,class_weight=\"balanced\").fit(\n",
        "    data.loc[:, [\"educ\", \"priorearn\"]].values, data.loc[:, \"foundjob\"].values\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
        "for i, (ax, tree) in enumerate(zip(axes.ravel(), forest.estimators_)):\n",
        "    ax.set_title(\"Tree {}\".format(i))\n",
        "    plot_interactive_tree.plot_tree_partition(\n",
        "        data.loc[:, [\"educ\", \"priorearn\"]].values,\n",
        "        data.loc[:, \"foundjob\"].values,\n",
        "        tree,\n",
        "        ax=ax,\n",
        "    )\n",
        "\n",
        "plot_2d_separator.plot_2d_separator(\n",
        "    forest,\n",
        "    data.loc[:, [\"educ\", \"priorearn\"]].values,\n",
        "    fill=True,\n",
        "    ax=axes[-1, -1],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[-1, -1].set_title(\"Random Forest\")\n",
        "plot_helpers.discrete_scatter(\n",
        "    data.loc[:, \"educ\"].values,\n",
        "    data.loc[:, \"priorearn\"].values,\n",
        "    data.loc[:, \"foundjob\"].values,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JExKzaLpgQOm"
      },
      "source": [
        "We only used two prediction features (prior earnings and education) for visualization. To get the best predictions, we should use all of our features. And to evaluate the quality of the prediction, we should hold out a test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plFtKVkUgn50"
      },
      "outputs": [],
      "source": [
        "# Define a matrix of features:\n",
        "X = data[[\"age\", \"priorearn\", \"educ\", \"female\", \"nonwhite\", \"married\"]]\n",
        "# hold out a test test:\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, data[\"foundjob\"], random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR1TkSjfhH-Y"
      },
      "source": [
        "Try on your own: grow a forest with 500 trees using the training set, and evaluate the prediction accuracy on the test set. Hint: you can evaluate the prediction accuracy by doing `forest.score(X_test,y_test)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocK-BWY8k5Wf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU_aIhS7k-SQ"
      },
      "source": [
        "##Cheat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovk5JDEWk5uk"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators=500, random_state=2).fit(X_train, y_train)\n",
        "forest.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "Cy24QHqODiRE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alI0KS2fZhI_"
      },
      "source": [
        "So much for predicting _outcomes_. We want to predict causal effects. Back to the whiteboard!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional regression-based heterogeneous treatment effects"
      ],
      "metadata": {
        "id": "9LSsdf4dtAqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back to NLSY example. Let's see how the effect of attending a private college varies by whether a parent is college educated. Let's define a variable, $parentcollege$, equal to one if either parent attended college, and zero otherwise:"
      ],
      "metadata": {
        "id": "9FYdqGZBv8Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlsy['parentcollege'] = ((nlsy['dadcollege'] == 1) | (nlsy['momcollege'] == 1)).astype(int) # astype(int) makes the values to be 0/1 instead of False/True"
      ],
      "metadata": {
        "id": "dELSy0sswaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's estimate the effect of private college among those with no parent who went to college:"
      ],
      "metadata": {
        "id": "aQxYt94-zne-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restrict to obsevations where parentcollege==0. No longer need to control separately for dadcollege, momcollege\n",
        "rhs = sm.add_constant(nlsy.loc[nlsy['parentcollege']==0,[\"privatecollege\", \"asvab\"]])\n",
        "model = sm.OLS(nlsy.loc[nlsy['parentcollege']==0,[\"annualearnings\"]], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "mBATFVQOtGjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the effect compare to the effect in the full sample?"
      ],
      "metadata": {
        "id": "r07pVZru06Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On your own: run the regression among those where at least one parent went to college."
      ],
      "metadata": {
        "id": "ciinVtoy0-av"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZYLLwbW1Y-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cheat"
      ],
      "metadata": {
        "id": "b1U7wShx045Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rhs = sm.add_constant(nlsy.loc[nlsy['parentcollege']==1,[\"privatecollege\", \"asvab\"]])\n",
        "model = sm.OLS(nlsy.loc[nlsy['parentcollege']==1,[\"annualearnings\"]], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "lacmZIDn1XwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "hAXWfKdh1ogg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the effect compare to that among those where neither parent went to college?"
      ],
      "metadata": {
        "id": "KbVRFhSj1tD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On your own: run as a single regression where you include interactions between $privatecollege$ and $parentcollege$, and between $asvab$ and $parentcollege$:"
      ],
      "metadata": {
        "id": "WS3i7V6n11Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7__u2l11_gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cheat"
      ],
      "metadata": {
        "id": "kBv-Q3mm1_4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlsy['privateXparent']=nlsy['privatecollege']*nlsy['parentcollege']\n",
        "nlsy['asvabXparent']=nlsy['asvab']*nlsy['parentcollege']\n",
        "rhs = sm.add_constant(nlsy.loc[:,[\"privatecollege\",\"privateXparent\", \"asvabXparent\",\"parentcollege\",\"asvab\"]])\n",
        "model = sm.OLS(nlsy.loc[:,[\"annualearnings\"]], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "qTRmsyec2BgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "hOBFLjDJ4BKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do the single-regression results compare to the separate regressions?"
      ],
      "metadata": {
        "id": "bk6O6WTa4CTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back to the whiteboard!"
      ],
      "metadata": {
        "id": "-LvQptJ04Glx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_J_iK_BmyTB"
      },
      "source": [
        "# Using Machine Learning to Predict Heterogeneous Treatment Effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9WBzU6Xn8Ux"
      },
      "source": [
        "## Key Challenge: Algorithms tailored for predicting outcomes can do poorly when predicting treatment effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTTUnLrowli"
      },
      "source": [
        "### Factors that strongly predict outcomes may not strongly predict treatment effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THdqEG_Lo4wu"
      },
      "source": [
        "$Y_i$: spending on a Lexus\n",
        "\n",
        "$D_i$: seeing an online ad for a Lexus\n",
        "\n",
        "$\\ln Y_i=\\beta_0+\\beta_1 age_i +\\beta_2 male_i + \\beta_3 D_i+\\beta_4 D_i \\times male_i +\\varepsilon_i$\n",
        "\n",
        "How do outcomes vary by age? (A lot if $\\beta_1$ is big)\n",
        "\n",
        "How do treatment effects vary by age? (not at all!)\n",
        "\n",
        "What do treatment effects vary by? (gender!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx8mK_rg2cyj"
      },
      "source": [
        "Let's simulate some data to show what happens when we try to use algorithm tailored to predicting outcomes for predicting treatment effects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsBtHlR33VrH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdDI1IwMqp5l"
      },
      "outputs": [],
      "source": [
        "# define parameters\n",
        "n = 1000  # sample size\n",
        "p = 0.5  # probability of seeing the ad\n",
        "beta0 = 0\n",
        "beta1 = 0.2  # effect of age\n",
        "beta2 = (\n",
        "    -0.025\n",
        ")  # difference in average spending between males and females who don't see the ad ()\n",
        "beta3 = 0  # effect of treatment among females\n",
        "beta4 = 0.05  # differential effect of treatment among males compared to females\n",
        "sigeps = 0.02  # residual variance of outcome\n",
        "\n",
        "# generate some fake data\n",
        "age = np.random.randint(low=18, high=61, size=(n, 1))\n",
        "male = np.random.randint(low=0, high=2, size=(n, 1))\n",
        "d = np.random.rand(n, 1) > (1 - p)\n",
        "epsilon = sigeps * np.random.randn(n, 1)\n",
        "lny = beta0 + beta1 * age + beta2 * male + beta3 * d + beta4 * d * male + epsilon\n",
        "\n",
        "# assemble as dataframe\n",
        "fakedata = pd.DataFrame(\n",
        "    np.concatenate((lny, d, age, male), axis=1), columns=[\"lny\", \"d\", \"age\", \"male\"]\n",
        ")\n",
        "fakedata.feature_names = [\"age\", \"male\"]\n",
        "x0 = fakedata.loc[d == 0, [\"age\", \"male\"]]\n",
        "x1 = fakedata.loc[d == 1, [\"age\", \"male\"]]\n",
        "y0 = fakedata.loc[d == 0, [\"lny\"]]\n",
        "y1 = fakedata.loc[d == 1, [\"lny\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd1uLAZk3vfG"
      },
      "source": [
        "Try on your own: fit two trees (call them `tree0` and `tree1`), each with `max_depth=2` to predict the outcome separately in the untreated ($D_i=0$) and treated ($D_i=1$) samples, using `x0` and `x1`, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LshTzl_54vSF"
      },
      "outputs": [],
      "source": [
        "# fit trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCdDGq0s4_z6"
      },
      "outputs": [],
      "source": [
        "# display trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8kmDmNp5B0m"
      },
      "source": [
        "###Cheat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1nnDYQn4xXN"
      },
      "outputs": [],
      "source": [
        "# fit trees\n",
        "tree1 = DecisionTreeRegressor(max_depth=2).fit(x1, y1)\n",
        "tree0 = DecisionTreeRegressor(max_depth=2).fit(x0, y0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQJoFuHh5IhF"
      },
      "outputs": [],
      "source": [
        "# display trees\n",
        "print(\"Treated tree:\")\n",
        "plot_tree(tree1, filled=True, feature_names=fakedata.feature_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c-DI__o5NpF"
      },
      "outputs": [],
      "source": [
        "print(\"Untreated tree:\")\n",
        "plot_tree(tree0, filled=True, feature_names=fakedata.feature_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "NVnZdvKbDv52"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVX__Pvu7EWU"
      },
      "source": [
        "Which variable(s) did the trees key in on? Why? Would these trees be useful for predicting treatment effects? Why or why not?\n",
        "\n",
        "How do we fix the problem?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Honest trees can exaggerate differences between groups"
      ],
      "metadata": {
        "id": "UQWeMjAC_GOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate a bunch of predictors:\n",
        "x1=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x2=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x3=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x4=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x5=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x6=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x7=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x8=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x9=np.random.randint(low=0,high=2,size=(n,1))\n",
        "x10=np.random.randint(low=0,high=2,size=(n,1))\n",
        "\n",
        "# Each of these predictors affects the outcome with coefficient = 1:\n",
        "y=x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+epsilon\n",
        "\n",
        "# Let's put these features in a matrix:\n",
        "predictors=np.concatenate((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10),axis=1)\n",
        "predictor_names=['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']"
      ],
      "metadata": {
        "id": "FeKHAzWV_UWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On your own: grow and display a tree (max_depth=2) to predict y on the basis of these features"
      ],
      "metadata": {
        "id": "66U-hs1S_ghJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "biyCtP4G_qBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheat"
      ],
      "metadata": {
        "id": "7TTzARZg_qbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dishonest=DecisionTreeRegressor(max_depth=2)\n",
        "dishonest.fit(predictors,y)\n",
        "d=tree.plot_tree(dishonest,filled=True,feature_names=predictor_names)"
      ],
      "metadata": {
        "id": "t4sagKVQ_rw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion:"
      ],
      "metadata": {
        "id": "Z7jozB8d_sgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to our \"model\" for y, what should be the difference between outcomes in neighboring leaves from the same node? (one!) What are the observed differences in the tree? (greater than one!)\n",
        "\n",
        "Solution: Honest trees, or double-sample trees, use a subset of the training set to grow the tree, and another subset to estimate means in each leaf"
      ],
      "metadata": {
        "id": "Y8l3AIy2_teb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Honest Trees"
      ],
      "metadata": {
        "id": "vb3eqYMOChnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select observations to be the training set:\n",
        "train=np.random.randint(low=0,high=2,size=n)==1"
      ],
      "metadata": {
        "id": "AwoFweJLCkKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On your own: grow a tree using the training set (max_depth=2), and display it."
      ],
      "metadata": {
        "id": "0nGbN9t2Cu3f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GDRb6gxC5Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheat"
      ],
      "metadata": {
        "id": "rRGBtqS4C5gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grow tree on training set:\n",
        "dt = DecisionTreeRegressor(max_depth=2)\n",
        "dt.fit(predictors[train,:],y[train])\n",
        "d=tree.plot_tree(dt,filled=True,feature_names=predictor_names)"
      ],
      "metadata": {
        "id": "y2WPzDiBC6_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "-USfmbSwC71r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use the estimation set to calculate the means in each leaf:"
      ],
      "metadata": {
        "id": "J7-HvMd5C9r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leaves=dt.apply(predictors[~train])\n",
        "yest=y[~train]\n",
        "honest=dt\n",
        "n_nodes = honest.tree_.node_count\n",
        "for ii in range(n_nodes):\n",
        "  if honest.tree_.children_left[ii]==-1: # means that the current node is a leaf\n",
        "    estii=yest[leaves==ii]\n",
        "    honest.tree_.value[ii]=estii.mean() # replace the leaf's value with the estimation set's mean\n",
        "\n",
        "d=tree.plot_tree(honest,filled=True,feature_names=predictor_names)"
      ],
      "metadata": {
        "id": "s_o70q5vDEar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The leaf means are not nearly as extreme as in the \"dishonest\" tree that uses the training observations to construct the predictions"
      ],
      "metadata": {
        "id": "pyqNaIoJDHIW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ImW8AlReB-f"
      },
      "source": [
        "## Random Causal Forest: Simulated Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCJz8T_m2qfZ"
      },
      "outputs": [],
      "source": [
        "# Install econml\n",
        "%pip install econml #&> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJmkYkVaOvW3"
      },
      "outputs": [],
      "source": [
        "from econml.dml import CausalForestDML as CausalForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OCVpZR7tA-V"
      },
      "outputs": [],
      "source": [
        "# NOTE: If you are getting `np.int` error, do the following:\n",
        "# pip install --force-reinstall numpy==1.23.5\n",
        "# There is a fix for the new numpy version, but it's not released yet:\n",
        "# https://github.com/py-why/EconML/commit/0be16255f10853fc9fe0774cb5649e051dc55dff\n",
        "\n",
        "# Instantiate the Causal Forest\n",
        "estimator = CausalForest(n_estimators=500, discrete_treatment=True, criterion=\"het\")\n",
        "\n",
        "# Grow the forest\n",
        "estimator.fit(\n",
        "    fakedata[\"lny\"], fakedata[\"d\"], X=fakedata[[\"age\", \"male\"]]  # outcome  # treatment\n",
        ")  # prediction features\n",
        "\n",
        "# Predict effects for each observation based on its characteristics:\n",
        "effects = estimator.effect(fakedata[[\"age\", \"male\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFtL_AJG9CAA"
      },
      "source": [
        "Let's see how well it did at estimating effects among men and women:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqoiopLL4v8J"
      },
      "outputs": [],
      "source": [
        "malefx = effects[fakedata[\"male\"].values == 1]\n",
        "malefx.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uai_wDHf428w"
      },
      "outputs": [],
      "source": [
        "femalefx = effects[fakedata[\"male\"].values == 0]\n",
        "femalefx.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctplR0SR9sBE"
      },
      "source": [
        "How did our causal forest do at getting effects right for men and women? Let's see how it does on the age profile:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPDiUMH17KDN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "maleage = fakedata[\"age\"].iloc[fakedata[\"male\"].values == 1]\n",
        "femaleage = fakedata[\"age\"].iloc[fakedata[\"male\"].values == 0]\n",
        "\n",
        "ax.scatter(maleage, malefx, label=\"males\")\n",
        "ax.scatter(femaleage, femalefx, label=\"females\")\n",
        "ax.legend()\n",
        "plt.title(\"Estimated Treatment effects\")\n",
        "plt.xlabel(\"age\")\n",
        "plt.ylabel(\"treatment effect\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY6X9FMo9nzN"
      },
      "source": [
        "A little noisy on the age profile (which should be flat) but does get the difference between men and women!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Qj_chk_RxA"
      },
      "source": [
        "## Random Causal Forest: Predict the effects of job training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gu4yXtj_p1_"
      },
      "source": [
        "We are ready to apply machine learning to predict causal effects in a real-life setting: how do the effects of job training vary by an individual's characteristics? We will use data from the National Job Training Partnership study, a large-scale randomized evaluation of a publicly subsidized job training program for disadvantaged youth and young adults. Why would we care how the effects of a subsidized job training program vary by a person's characteristics?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_9P5WPQA-LD"
      },
      "source": [
        "We will use the JTPA evaluation dataset, which contains observations on about 14,000 individuals, some of whom were randomized to participate in job training ($z_i = 1$) and others who were not ($z_i = 0$).\n",
        "\n",
        "To do on your own:\n",
        "\n",
        "- load the dataset from the `data/jtpahet.csv`\n",
        "- define the outcome vector (call it `y`) to be the column labeled `foundjob`\n",
        "- define the randomized assignment indicator (call it `z`) to be the column labeled `z`\n",
        "- define the feature vector (call it `x`) to be all columns except `foundjob`, `z`, and `enroll`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxlaYZBvBL_K"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "\n",
        "# define the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRi_NHFHBMbT"
      },
      "source": [
        "### Cheat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA8jeMVrYyNM"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\n",
        "    \"data/jtpahet.csv\"\n",
        ")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lvqN0FkmYZc"
      },
      "outputs": [],
      "source": [
        "y = data[\"foundjob\"]\n",
        "z = data[\"z\"]\n",
        "x = data.drop([\"foundjob\", \"z\", \"enroll\"], axis=1)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrQYHqKWtp-a"
      },
      "source": [
        "### Regression to get average effect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUD92j-Y3nRE"
      },
      "source": [
        "On your own: run a linear regression of the outcome on the random assignment indicator, `z`. Since this was a randomized experiment, we don't need controls!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jqgYqcx3yEB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy2j0806315i"
      },
      "source": [
        "### Cheat:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOC7Ev8t34Dq"
      },
      "outputs": [],
      "source": [
        "rhs = sm.add_constant(\n",
        "    data[\"z\"]\n",
        ")  # you have to add the constant yourself with statsmodels!\n",
        "model = sm.OLS(data[\"foundjob\"], rhs)\n",
        "results = model.fit(cov_type=\"HC3\")  # heteroskedasticity-robust\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62yrByRIBk8Z"
      },
      "source": [
        "### Set up random forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4fwaxUtBqgN"
      },
      "source": [
        "So far, so good? Now create a random causal forest object, and fit it with outcome `y`, treatment variable `z`, and feature matrix `x`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoPlfQhdB459"
      },
      "outputs": [],
      "source": [
        "# On your own: create and fit random causal forest object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoHuWuUnB9LI"
      },
      "source": [
        "### Cheat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3UWboTmm2dn"
      },
      "outputs": [],
      "source": [
        "rcf = CausalForest(n_estimators=500, discrete_treatment=True, criterion=\"het\").fit(\n",
        "    y, z, X=x\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WniVmeMYCAS9"
      },
      "source": [
        "### Explore effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpCYhIH6CHQ1"
      },
      "source": [
        "Let's see what kind of heterogeneous effects our random causal forest predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXZ-maDVnjcf"
      },
      "outputs": [],
      "source": [
        "# calculate the predicted effects:\n",
        "insamplefx = rcf.effect(x)\n",
        "# plot a histogram of the estimated effects, with average effect overlaid\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.hist(insamplefx, bins=30, density=True)\n",
        "plt.axvline(rcf.ate_, color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
        "plt.suptitle(\"Estimated Treatment effects\")\n",
        "plt.title(\"ATE: {:.3g}\".format(rcf.ate_[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysSaIrbpCjgx"
      },
      "source": [
        "Let's visualize how these effects vary by prior earnings and education by making a heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7KqJyWaqgZJ"
      },
      "outputs": [],
      "source": [
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS6_MnlavsFn"
      },
      "outputs": [],
      "source": [
        "# create a grid of values for education and prior earnings:\n",
        "educgrid = np.arange(data[\"educ\"].values.min(), data[\"educ\"].values.max() + 1)\n",
        "earngrid = np.arange(\n",
        "    data[\"priorearn\"].values.min(), data[\"priorearn\"].values.max(), 5000\n",
        ")\n",
        "grid = pd.DataFrame(\n",
        "    itertools.product(educgrid, earngrid), columns=[\"educ\", \"priorearn\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dOzvR9AC277"
      },
      "source": [
        "We'll first visualize the effects among married, nonwhite females of average age:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alNQLH2WuzWU"
      },
      "outputs": [],
      "source": [
        "grid[\"age\"] = data[\"age\"].values.mean()  # set age to the average\n",
        "grid[\"female\"] = 1  # set female = 1\n",
        "grid[\"nonwhite\"] = 1  # set nonwhite = 1\n",
        "grid[\"married\"] = 1  # set married = 1\n",
        "# need to re-order the columns to match x:\n",
        "grid=grid[x.columns]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdQVCJVMDPJi"
      },
      "source": [
        "To do on your own: calculate the predicted effects for each \"observation\" in the grid:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpJtU9CMDaBG"
      },
      "outputs": [],
      "source": [
        "# gridfx = # uncomment and fill in on your own!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIzL26GBDavL"
      },
      "source": [
        "### Cheat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSqd6njlz3HI"
      },
      "outputs": [],
      "source": [
        "gridfx = rcf.effect(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oA4yTCCDmGL"
      },
      "source": [
        "### Visualize effects with a heatmap:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR7rKsiqokah"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.subplot()\n",
        "main = ax.scatter(\n",
        "    grid[\"educ\"], grid[\"priorearn\"], c=gridfx, cmap=\"plasma\", marker=\"s\", s=300\n",
        ")\n",
        "plt.suptitle(\"Estimated Treatment effects\")\n",
        "plt.title(\"Nonwhite married females\")\n",
        "plt.xlabel(\"years of education\")\n",
        "plt.ylabel(\"prior earnings\")\n",
        "\n",
        "# create an Axes on the right side of ax. The width of cax will be 5%\n",
        "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "plt.colorbar(main, cax=cax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM9p3yq0DxXP"
      },
      "source": [
        "To do on your own: make similar visualizations for males, singles, whites, different ages, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPlA-jY8D6DB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eU_aIhS7k-SQ",
        "M8kmDmNp5B0m",
        "pRi_NHFHBMbT",
        "Hy2j0806315i",
        "qoHuWuUnB9LI",
        "RIzL26GBDavL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}